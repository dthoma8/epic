{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.models.ldamodel as LDA\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import pickle \n",
    "import json, time, os, string\n",
    "\n",
    "# # Run these the first time you do this\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in list of text blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open('Brexit_text_list', 'rb') \n",
    "hit_text = pickle.load(filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing functions for entire text blocks\n",
    "\n",
    "def LemmatizerBlock(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    wnl = WordNetLemmatizer()\n",
    "    tokens = [wnl.lemmatize(t) for t in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def FilterPunc(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def stopwordRemovalBlock(text, stop_words):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def clean(text, stop_words):\n",
    "#     text = text.lower()\n",
    "    no_stop = stopwordRemovalBlock(text, stop_words)\n",
    "    no_punc = FilterPunc(no_stop)\n",
    "    return no_punc\n",
    "\n",
    "# Gensim prefers BOW corpora to be a list of lists of words for each document \n",
    "def gensimPrep(list_of_texts):\n",
    "    tokenized = [word_tokenize(text) for text in list_of_texts]\n",
    "    return tokenized    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing and removing punctuation and converting to gensim's desired format\n",
    "lowered = [hit.lower() for hit in hit_text]\n",
    "no_punc = [FilterPunc(low) for low in lowered]\n",
    "to_gensim = gensimPrep(no_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up bi/trigram models\n",
    "bigram = gensim.models.Phrases(to_gensim, min_count=5, threshold=100) \n",
    "trigram = gensim.models.Phrases(bigram[to_gensim], threshold=100)  \n",
    "\n",
    "# Phrase the sentence to build bi/trigram models \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'the', 'first', 'of', 'two', 'extracts', 'from', 'their', 'new', 'book', 'liam', 'halligan', 'and', 'gerard', 'lyons', 'say', 'the', 'commonly', 'held', 'belief', 'that', 'britain', 'would', 'be', 'better', 'off', 'inside', 'the', 'single_market', 'and', 'customs_union', 'is', 'misconceived', 'there', 'has', 'been', 'much', 'talk', 'of', 'hard', 'brexit', 'versus', 'soft', 'brexit', 'such', 'labels', 'are', 'ubiquitous', 'during', 'these', 'article', 'negotiations', 'used', 'freely', 'by', 'the', 'broadcast', 'media', 'yet', 'they', 'are', 'partisan', 'and', 'deeply', 'misleading', 'hard', 'brexit', 'makes', 'leaving', 'the', 'european_union', 'sound', 'extreme', 'and', 'damaging', 'suggesting', 'and', 'a', 'bleak', 'economic', 'future', 'soft', 'brexit', 'conversely', 'conveys', 'a', 'comfortable', 'ongoing', 'relationship', 'with', 'the', 'eu', 'with', 'britain', 'still', 'part', 'of', 'the', 'club', 'leaving', 'the', 'single_market', 'and', 'the', 'customs_union', 'isn_t', 'hard', 'brexit', 'even', 'if', 'the', 'name', 'is', 'deliberately', 'coined', 'to', 'sound', 'painful', 'it', 'is', 'simply', 'brexit', 'staying', 'inside', 'the', 'eu', 's', 'two', 'main', 'legal', 'constructs', 'meanwhile', 'isn_t', 'a', 'harmonious', 'soft', 'brexit', 'it', 'amounts', 'instead', 'to', 'a', 'deliberate', 'and', 'cynical', 'failure', 'to', 'implement', 'the', 'referendum', 'result']\n"
     ]
    }
   ],
   "source": [
    "print(trigram_mod[bigram_mod[to_gensim[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the bigram model on the text\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "# Running the trigram model on the bigram model (Gensim works through this nested pattern)\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "# Removing stopwords from the nested lists using nltk defined stopwords\n",
    "def stopwordRemovalList(text, stop_words):\n",
    "    out_words = [w for w in text if not w in stop_words]\n",
    "    return out_words\n",
    "\n",
    "# Use spacy lemmatization and only keep the select parts of speech, runs somewhat slowly\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make trigrams and bigrams in the text, remove stopwords, and lemmatize\n",
    "trigrams = make_trigrams(to_gensim)\n",
    "stop_free = [stopwordRemovalList(text, stop) for text in trigrams]\n",
    "lemmatized_text = lemmatization(stop_free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating topic models with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First build the corpus in Gensim's required format\n",
    "id2word = corpora.Dictionary(final_output)   # Initialize a dictionary for indexing all unique words\n",
    "corpus = [id2word.doc2bow(text) for text in lemmatized_text] # Generate a list including all unique words anf their frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the topic model\n",
    "lda_model = LDA.LdaModel(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=5, \n",
    "                                       random_state=0,\n",
    "                                       update_every=1,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       alpha='auto',\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.014*\"say\" + 0.011*\"year\" + 0.009*\"business\" + 0.008*\"company\" + 0.007*\"uk\" + 0.007*\"bank\" + 0.007*\"datum\" + 0.006*\"new\" + 0.006*\"market\" + 0.005*\"also\"'),\n",
       " (1,\n",
       "  '0.010*\"people\" + 0.007*\"say\" + 0.007*\"go\" + 0.007*\"get\" + 0.007*\"make\" + 0.007*\"think\" + 0.006*\"time\" + 0.005*\"would\" + 0.005*\"take\" + 0.004*\"thing\"'),\n",
       " (2,\n",
       "  '0.009*\"trump\" + 0.007*\"say\" + 0.005*\"country\" + 0.005*\"world\" + 0.004*\"include\" + 0.004*\"american\" + 0.004*\"europe\" + 0.004*\"president\" + 0.003*\"refugee\" + 0.003*\"germany\"'),\n",
       " (3,\n",
       "  '0.021*\"say\" + 0.017*\"government\" + 0.015*\"would\" + 0.010*\"britain\" + 0.009*\"brexit\" + 0.009*\"uk\" + 0.007*\"deal\" + 0.007*\"make\" + 0.007*\"may\" + 0.006*\"vote\"'),\n",
       " (4,\n",
       "  '0.055*\"party\" + 0.037*\"labour\" + 0.020*\"tory\" + 0.016*\"election\" + 0.015*\"say\" + 0.014*\"conference\" + 0.014*\"conservative\" + 0.013*\"leader\" + 0.013*\"may\" + 0.012*\"johnson\"')]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the topics and the top 10 words in each \n",
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score:  0.41588594612823726\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the topic models with a coherence score (higher the better)\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=lemmatized_text, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the topic models for the visualizer\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "\n",
    "# Loads the visualization in another webpage \n",
    "pyLDAvis.show(vis)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving this because it takes a while to generate\n",
    "import pickle \n",
    "filehandler = open('LDAvis5Topic', 'wb') \n",
    "pickle.dump(vis, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load this in instead of running the .prepare block\n",
    "filehandler = open('LDAvis5Topic', 'rb') \n",
    "vis = pickle.load(filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, pyLDAvis.show() is not the best command\n",
      "      to use. Consider using pyLDAvis.display(), or pyLDAvis.enable_notebook().\n",
      "      See more information at http://pyLDAvis.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8889/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [09/Aug/2019 10:13:30] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Aug/2019 10:13:30] \"GET /LDAvis.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Aug/2019 10:13:30] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [09/Aug/2019 10:13:30] code 404, message Not Found\n",
      "127.0.0.1 - - [09/Aug/2019 10:13:30] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 60909)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\jdward\\appdata\\local\\continuum\\anaconda3\\envs\\elastic\\lib\\socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"c:\\users\\jdward\\appdata\\local\\continuum\\anaconda3\\envs\\elastic\\lib\\socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"c:\\users\\jdward\\appdata\\local\\continuum\\anaconda3\\envs\\elastic\\lib\\socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"c:\\users\\jdward\\appdata\\local\\continuum\\anaconda3\\envs\\elastic\\lib\\socketserver.py\", line 720, in __init__\n",
      "    self.handle()\n",
      "  File \"c:\\users\\jdward\\appdata\\local\\continuum\\anaconda3\\envs\\elastic\\lib\\http\\server.py\", line 426, in handle\n",
      "    self.handle_one_request()\n",
      "  File \"c:\\users\\jdward\\appdata\\local\\continuum\\anaconda3\\envs\\elastic\\lib\\http\\server.py\", line 414, in handle_one_request\n",
      "    method()\n",
      "  File \"c:\\users\\jdward\\appdata\\local\\continuum\\anaconda3\\envs\\elastic\\lib\\site-packages\\pyLDAvis\\_server.py\", line 52, in do_GET\n",
      "    self.send_error(404)\n",
      "  File \"c:\\users\\jdward\\appdata\\local\\continuum\\anaconda3\\envs\\elastic\\lib\\http\\server.py\", line 481, in send_error\n",
      "    self.wfile.write(body)\n",
      "  File \"c:\\users\\jdward\\appdata\\local\\continuum\\anaconda3\\envs\\elastic\\lib\\socketserver.py\", line 799, in write\n",
      "    self._sock.sendall(b)\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n",
      "----------------------------------------\n",
      "127.0.0.1 - - [09/Aug/2019 10:13:30] \"GET /LDAvis.js HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stopping Server...\n"
     ]
    }
   ],
   "source": [
    "pyLDAvis.show(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to use Mallet instead because the topics will probably be better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "os.environ['MALLET_HOME'] = r'C:\\Users\\jdward\\mallet-2.0.8\\mallet-2.0.8'\n",
    "mallet_path = r'C:\\Users\\jdward\\mallet-2.0.8\\mallet-2.0.8\\bin\\mallet' \n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.047*\"brexit\" + 0.033*\"deal\" + 0.032*\"uk\" + 0.032*\"britain\" + 0.025*\"talk\" + 0.020*\"british\" + 0.020*\"negotiation\" + 0.017*\"eu\" + 0.016*\"make\" + 0.015*\"leave\"'),\n",
       " (1,\n",
       "  '0.065*\"party\" + 0.051*\"labour\" + 0.021*\"election\" + 0.020*\"corbyn\" + 0.015*\"vote\" + 0.014*\"leader\" + 0.013*\"policy\" + 0.013*\"voter\" + 0.012*\"campaign\" + 0.012*\"conference\"'),\n",
       " (2,\n",
       "  '0.017*\"time\" + 0.011*\"bad\" + 0.011*\"thing\" + 0.010*\"turn\" + 0.009*\"back\" + 0.008*\"day\" + 0.008*\"good\" + 0.007*\"fact\" + 0.007*\"long\" + 0.007*\"end\"'),\n",
       " (3,\n",
       "  '0.015*\"system\" + 0.012*\"risk\" + 0.011*\"change\" + 0.010*\"technology\" + 0.008*\"project\" + 0.008*\"energy\" + 0.008*\"model\" + 0.007*\"work\" + 0.007*\"power\" + 0.007*\"create\"'),\n",
       " (4,\n",
       "  '0.054*\"government\" + 0.033*\"brexit\" + 0.019*\"parliament\" + 0.018*\"bill\" + 0.017*\"vote\" + 0.017*\"law\" + 0.015*\"labour\" + 0.015*\"minister\" + 0.013*\"mps\" + 0.012*\"leave\"'),\n",
       " (5,\n",
       "  '0.026*\"company\" + 0.020*\"business\" + 0.015*\"market\" + 0.014*\"year\" + 0.013*\"london\" + 0.013*\"bank\" + 0.013*\"firm\" + 0.010*\"big\" + 0.010*\"city\" + 0.009*\"service\"'),\n",
       " (6,\n",
       "  '0.012*\"campaign\" + 0.012*\"trump\" + 0.011*\"medium\" + 0.011*\"bbc\" + 0.010*\"political\" + 0.009*\"news\" + 0.009*\"ukip\" + 0.009*\"write\" + 0.007*\"claim\" + 0.007*\"report\"'),\n",
       " (7,\n",
       "  '0.042*\"uk\" + 0.028*\"trade\" + 0.017*\"brexit\" + 0.016*\"country\" + 0.016*\"government\" + 0.014*\"britain\" + 0.011*\"global\" + 0.011*\"world\" + 0.010*\"economy\" + 0.009*\"business\"'),\n",
       " (8,\n",
       "  '0.029*\"people\" + 0.021*\"feel\" + 0.015*\"woman\" + 0.013*\"man\" + 0.012*\"make\" + 0.011*\"thing\" + 0.010*\"talk\" + 0.009*\"view\" + 0.009*\"politic\" + 0.008*\"good\"'),\n",
       " (9,\n",
       "  '0.036*\"brexit\" + 0.029*\"tory\" + 0.023*\"speech\" + 0.021*\"prime_minister\" + 0.019*\"johnson\" + 0.018*\"party\" + 0.018*\"conservative\" + 0.017*\"cabinet\" + 0.014*\"conference\" + 0.011*\"week\"'),\n",
       " (10,\n",
       "  '0.011*\"britain\" + 0.011*\"world\" + 0.010*\"british\" + 0.009*\"country\" + 0.009*\"war\" + 0.009*\"today\" + 0.007*\"international\" + 0.007*\"security\" + 0.007*\"day\" + 0.007*\"trump\"'),\n",
       " (11,\n",
       "  '0.029*\"year\" + 0.020*\"rise\" + 0.018*\"growth\" + 0.017*\"bank\" + 0.015*\"fall\" + 0.014*\"increase\" + 0.014*\"economy\" + 0.013*\"month\" + 0.012*\"price\" + 0.011*\"economic\"'),\n",
       " (12,\n",
       "  '0.012*\"world\" + 0.011*\"make\" + 0.010*\"write\" + 0.010*\"book\" + 0.008*\"work\" + 0.007*\"story\" + 0.007*\"year\" + 0.007*\"film\" + 0.007*\"history\" + 0.007*\"show\"'),\n",
       " (13,\n",
       "  '0.037*\"referendum\" + 0.027*\"vote\" + 0.024*\"government\" + 0.021*\"independence\" + 0.017*\"spain\" + 0.017*\"catalonia\" + 0.015*\"people\" + 0.014*\"catalan\" + 0.012*\"spanish\" + 0.009*\"police\"'),\n",
       " (14,\n",
       "  '0.023*\"business\" + 0.020*\"datum\" + 0.020*\"people\" + 0.014*\"make\" + 0.011*\"company\" + 0.009*\"money\" + 0.008*\"customer\" + 0.008*\"airline\" + 0.008*\"world\" + 0.007*\"social\"'),\n",
       " (15,\n",
       "  '0.041*\"europe\" + 0.027*\"european\" + 0.021*\"germany\" + 0.020*\"country\" + 0.017*\"german\" + 0.012*\"party\" + 0.011*\"merkel\" + 0.010*\"france\" + 0.010*\"european_union\" + 0.009*\"election\"'),\n",
       " (16,\n",
       "  '0.013*\"city\" + 0.008*\"good\" + 0.008*\"game\" + 0.008*\"include\" + 0.008*\"year\" + 0.007*\"back\" + 0.007*\"home\" + 0.006*\"club\" + 0.006*\"big\" + 0.006*\"team\"'),\n",
       " (17,\n",
       "  '0.031*\"people\" + 0.019*\"british\" + 0.016*\"child\" + 0.015*\"live\" + 0.015*\"school\" + 0.012*\"university\" + 0.012*\"year\" + 0.011*\"young\" + 0.011*\"time\" + 0.010*\"society\"'),\n",
       " (18,\n",
       "  '0.021*\"make\" + 0.014*\"important\" + 0.011*\"work\" + 0.010*\"great\" + 0.010*\"give\" + 0.009*\"time\" + 0.009*\"support\" + 0.009*\"issue\" + 0.008*\"people\" + 0.008*\"hope\"'),\n",
       " (19,\n",
       "  '0.029*\"work\" + 0.024*\"job\" + 0.022*\"uk\" + 0.020*\"worker\" + 0.015*\"government\" + 0.014*\"pay\" + 0.012*\"people\" + 0.011*\"year\" + 0.010*\"home\" + 0.010*\"immigration\"')]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the topics and the top 10 words in each \n",
    "ldamallet.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.4643946777377191\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=lemmatized_text, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('Coherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
